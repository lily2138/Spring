{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBM\n",
    "    DecisionTree -->\n",
    "                    Ensemble\n",
    "    1) Bagging 알고리즘 ---> RandomForest Machine\n",
    "    2) Boosting 알고리즘 ---> GradientBoosting Machine\n",
    "    \n",
    "        GradientBoosting Machine\n",
    "        모델을 학습하고 결과를 예측... 이때 잘못예측한 결과에 따라서 데이타(속성)의 가중치를 조절해가면서 학습하는 알고리즘이 구현되어 있다. 이때, 속성들의 가중치를 업데이트 하는 방법으로 경사하강법(Gradient Descent)가 사용된다.\n",
    "        GradientBoosting Machine에서는 그렇기 때문에 이전에 볼 수 없었던 하이퍼파라미터 값들도 많이 늘어나는데 그중에 가장 대표적인 하이퍼 파라미터가 learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "훈련 세트 정확도 : 1.000000\n",
      "테스트 세트 정확도 : 0.951049\n"
     ]
    }
   ],
   "source": [
    "gbc=GradientBoostingClassifier(random_state=0)      # 1.0 / 0.95\n",
    "\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "print('*'*50)\n",
    "print('훈련 세트 정확도 : {:3f}'.format(gbc.score(X_train, y_train)))\n",
    "print('테스트 세트 정확도 : {:3f}'.format(gbc.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "훈련 세트 정확도 : 0.990610\n",
      "테스트 세트 정확도 : 0.979021\n"
     ]
    }
   ],
   "source": [
    "gbc=GradientBoostingClassifier(random_state=0, max_depth=1)\n",
    "\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "print('*'*50)\n",
    "print('훈련 세트 정확도 : {:3f}'.format(gbc.score(X_train, y_train)))\n",
    "print('테스트 세트 정확도 : {:3f}'.format(gbc.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "훈련 세트 정확도 : 0.983568\n",
      "테스트 세트 정확도 : 0.965035\n"
     ]
    }
   ],
   "source": [
    "gbc=GradientBoostingClassifier(random_state=0, learning_rate=0.01)\n",
    "\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "print('*'*50)\n",
    "print('훈련 세트 정확도 : {:3f}'.format(gbc.score(X_train, y_train)))\n",
    "print('테스트 세트 정확도 : {:3f}'.format(gbc.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search\n",
    "    우리가 지정해준 몇가지의 잠재적인 파라미터 후보군들의 조합중에서 가장 Best의 조합을 찾아준다. 다시말해서 우리가 하나하나 일일이 파라미터들을 대입해 가면서 작업하는 부분을 GridSearch가 알아서 자동으로 해준다고 보면 된다\n",
    "    이런 라이브러리를 sklearn에서 제공한다.\n",
    "    \n",
    "    하지만, 가장 큰 단점은 우리가 지정해준 하이퍼파라미터 후보군의 갯수만큼 비례하여 시간이 늘어나기 때문에 생각보다 매우 긴 시간이 소요된다.\n",
    "   \n",
    "    이 GridSearch sklearn 패키지에서 model_selection에 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators' : [100, 150, 200, 250],\n",
    "    'max_depth' : [4,6,9],\n",
    "    'learning_rate':[0.1,0.01,0.001]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=GradientBoostingClassifier(), n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.1, 0.01, 0.001],\n",
       "                         'max_depth': [4, 6, 9],\n",
       "                         'n_estimators': [100, 150, 200, 250]})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbmodel = GradientBoostingClassifier()\n",
    "grid_search = GridSearchCV(gbmodel,\n",
    "                          param_grid,\n",
    "                          n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 200}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 정확도 : 1.000000\n",
      "테스트 세트 정확도 : 0.979021\n"
     ]
    }
   ],
   "source": [
    "print('훈련 세트 정확도 : {:3f}'.format(newmodel.score(X_train, y_train)))\n",
    "print('테스트 세트 정확도 : {:3f}'.format(newmodel.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 새로운 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "훈련 세트 정확도 : 1.000000\n",
      "테스트 세트 정확도 : 0.979021\n"
     ]
    }
   ],
   "source": [
    "newmodel = GradientBoostingClassifier(random_state=100, learning_rate=0.1, max_depth=4, n_estimators=200)\n",
    "\n",
    "newmodel.fit(X_train, y_train)\n",
    "\n",
    "print('*'*50)\n",
    "print('훈련 세트 정확도 : {:3f}'.format(newmodel.score(X_train, y_train)))\n",
    "print('테스트 세트 정확도 : {:3f}'.format(newmodel.score(X_test, y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
